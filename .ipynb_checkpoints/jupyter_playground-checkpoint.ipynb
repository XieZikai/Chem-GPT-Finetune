{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e83b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data.data_preprocess import generate_classification_dataset, generate_core_train_test_by_equipartition, write_file, generate_classification_dataset_by_equipartition\n",
    "import openai\n",
    "from tuner import Tuner, make_output_dir\n",
    "import json\n",
    "import os\n",
    "from openai.cli import FineTune\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from gpt_attacker import Attacker\n",
    "import math\n",
    "import re\n",
    "import copy\n",
    "from utils import replace_smiles_with_missing\n",
    "import chemprop\n",
    "import tqdm\n",
    "from io import StringIO\n",
    "from utils import SMART_LIST\n",
    "import warnings\n",
    "\n",
    "openai.api_key = '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'\n",
    "COLUMN = 'LUMO'\n",
    "NUM_CLASS = 3\n",
    "SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0a54c",
   "metadata": {},
   "source": [
    "# 1. Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e01e2e",
   "metadata": {},
   "source": [
    "# 2. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a73ece",
   "metadata": {},
   "source": [
    "# 3. Experiment Results Collection & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa8a362",
   "metadata": {},
   "source": [
    "## Chemprop result collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\Users\\darkn\\PycharmProjects\\ChemGPT\\out\\new_data_gpt\\small_molecule'\n",
    "folders = os.listdir(PATH)\n",
    "\n",
    "results_chemprop = {}\n",
    "\n",
    "# for folder in os.listdir(PATH):\n",
    "for folder in folders:\n",
    "    if not os.path.exists(os.path.join(PATH, folder + '/model_checkpoint/fold_0')):\n",
    "        continue\n",
    "    \n",
    "    arguments = [\n",
    "        '--test_path', os.path.join(PATH, folder + '/valid.csv'),  # \n",
    "        '--checkpoint_dir', os.path.join(PATH, folder + '/model_checkpoint/fold_0'),\n",
    "        '--preds_path',  os.path.join(PATH, folder + '/pred.csv')\n",
    "    ]\n",
    "    args = chemprop.args.PredictArgs().parse_args(arguments)\n",
    "    model_objects = chemprop.train.load_model(args=args)\n",
    "    \n",
    "    \n",
    "    preds = chemprop.train.make_predictions(args=args, model_objects=model_objects)\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(PATH, folder + '/valid.csv'))\n",
    "    y_true = df['target'].to_list()\n",
    "    y_pred = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, pred in enumerate(preds):\n",
    "        total += 1\n",
    "        p = np.argmax(pred)\n",
    "        y_pred.append(p)\n",
    "        if p == y_true[i]:\n",
    "            correct += 1\n",
    "    print (folder, ': ', correct/total)\n",
    "    results_chemprop[folder] = correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f1c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "homo_result_chemprop = {}\n",
    "lumo_result_chemprop = {}\n",
    "\n",
    "splits = ['0.2', '0.4', '0.6', '0.8']\n",
    "\n",
    "for split in splits:\n",
    "    keys = [key for key in results_chemprop.keys() if split in key and 'HOMO' in key]\n",
    "    total = 0\n",
    "    for key in keys:\n",
    "        total += results_chemprop[key]\n",
    "    total = total / 3\n",
    "    homo_result_chemprop[split] = total\n",
    "    \n",
    "    keys = [key for key in results_chemprop.keys() if split in key and 'LUMO' in key]\n",
    "    total = 0\n",
    "    for key in keys:\n",
    "        total += results_chemprop[key]\n",
    "    total = total / 3\n",
    "    lumo_result_chemprop[split] = total\n",
    "\n",
    "print(homo_result_chemprop, lumo_result_chemprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\Users\\darkn\\PycharmProjects\\ChemGPT\\out\\new_data_gpt\\small_molecule_small_dataset'\n",
    "folders = os.listdir(PATH)\n",
    "\n",
    "results_chemprop = {}\n",
    "\n",
    "# for folder in os.listdir(PATH):\n",
    "for folder in folders:\n",
    "    if not os.path.exists(os.path.join(PATH, folder + '/model_checkpoint/fold_0')):\n",
    "        continue\n",
    "    \n",
    "    arguments = [\n",
    "        '--test_path', os.path.join(PATH, folder + '/valid.csv'),  # \n",
    "        '--checkpoint_dir', os.path.join(PATH, folder + '/model_checkpoint/fold_0'),\n",
    "        '--preds_path',  os.path.join(PATH, folder + '/pred.csv')\n",
    "    ]\n",
    "    args = chemprop.args.PredictArgs().parse_args(arguments)\n",
    "    model_objects = chemprop.train.load_model(args=args)\n",
    "    \n",
    "    \n",
    "    preds = chemprop.train.make_predictions(args=args, model_objects=model_objects)\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(PATH, folder + '/valid.csv'))\n",
    "    y_true = df['target'].to_list()\n",
    "    y_pred = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, pred in enumerate(preds):\n",
    "        total += 1\n",
    "        p = np.argmax(pred)\n",
    "        y_pred.append(p)\n",
    "        if p == y_true[i]:\n",
    "            correct += 1\n",
    "    print (folder, ': ', correct/total)\n",
    "    results_chemprop[folder] = correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e4849",
   "metadata": {},
   "outputs": [],
   "source": [
    "homo_result_chemprop = {}\n",
    "lumo_result_chemprop = {}\n",
    "\n",
    "splits = ['0.01', '0.02', '0.1']\n",
    "\n",
    "for split in splits:\n",
    "    keys = [key for key in results_chemprop.keys() if split in key and 'HOMO' in key]\n",
    "    total = 0\n",
    "    for key in keys:\n",
    "        total += results_chemprop[key]\n",
    "    total = total / 3\n",
    "    homo_result_chemprop[split] = total\n",
    "    \n",
    "    keys = [key for key in results_chemprop.keys() if split in key and 'LUMO' in key]\n",
    "    total = 0\n",
    "    for key in keys:\n",
    "        total += results_chemprop[key]\n",
    "    total = total / 3\n",
    "    lumo_result_chemprop[split] = total\n",
    "\n",
    "print(homo_result_chemprop, lumo_result_chemprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafefdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\Users\\darkn\\PycharmProjects\\ChemGPT\\out\\new_data_gpt'\n",
    "folders = os.listdir(PATH)\n",
    "\n",
    "results_chemprop = {}\n",
    "\n",
    "# for folder in os.listdir(PATH):\n",
    "for folder in folders:\n",
    "    if not os.path.exists(os.path.join(PATH, folder + '/model_checkpoint/fold_0')):\n",
    "        continue\n",
    "    \n",
    "    arguments = [\n",
    "        '--test_path', os.path.join(PATH, folder + '/valid.csv'),  # \n",
    "        '--checkpoint_dir', os.path.join(PATH, folder + '/model_checkpoint/fold_0'),\n",
    "        '--preds_path',  os.path.join(PATH, folder + '/pred.csv')\n",
    "    ]\n",
    "    args = chemprop.args.PredictArgs().parse_args(arguments)\n",
    "    model_objects = chemprop.train.load_model(args=args)\n",
    "    \n",
    "    \n",
    "    preds = chemprop.train.make_predictions(args=args, model_objects=model_objects)\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(PATH, folder + '/valid.csv'))\n",
    "    y_true = df['target'].to_list()\n",
    "    y_pred = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, pred in enumerate(preds):\n",
    "        total += 1\n",
    "        p = np.argmax(pred)\n",
    "        y_pred.append(p)\n",
    "        if p == y_true[i]:\n",
    "            correct += 1\n",
    "    print (folder, ': ', correct/total)\n",
    "    results_chemprop[folder] = correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05930de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df82f4c3",
   "metadata": {},
   "source": [
    "# 4. Ablation Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88eb45d",
   "metadata": {},
   "source": [
    "## Ablation: Replacement test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d767b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacement test\n",
    "path = r'C:\\Users\\shibi\\PycharmProjects\\gptchem\\out\\new_data_gpt\\small_molecule\\20230701_152139__0.4_LUMO_1'\n",
    "model_id = 'ada:ft-birmingham-digital-chemistry-2023-07-03-13-39-02'\n",
    "attacker = Attacker(model_id)\n",
    "\n",
    "result = attacker.replacement_test(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219888df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacement test result collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04755458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fda50cc6",
   "metadata": {},
   "source": [
    "## Ablation: Combine core data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8708e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_LISTS = [\n",
    "    ['core_16392',\n",
    "     'core_16404',\n",
    "     'core_16583',\n",
    "     'core_14647',\n",
    "     'core_14707'\n",
    "    ], \n",
    "    ['core_7123',\n",
    "     'core_7188',\n",
    "     'core_8000'\n",
    "    ],\n",
    "    ['core_11149',\n",
    "     'core_11127',\n",
    "     'core_11138'\n",
    "    ],\n",
    "    ['core_16392',\n",
    "     'core_16404',\n",
    "     'core_16583',\n",
    "     'core_14647',\n",
    "     'core_14707',\n",
    "     'core_7123',\n",
    "     'core_7188',\n",
    "     'core_8000'\n",
    "    ],\n",
    "    ['core_16392',\n",
    "     'core_16404',\n",
    "     'core_16583',\n",
    "     'core_14647',\n",
    "     'core_14707',\n",
    "     'core_7123',\n",
    "     'core_7188',\n",
    "     'core_8000',\n",
    "     'core_11149',\n",
    "     'core_11127',\n",
    "     'core_11138'\n",
    "    ]\n",
    "]\n",
    "\n",
    "NAME_POSTFIXS = [\n",
    "    '12345',\n",
    "    '678',\n",
    "    '91011',\n",
    "    '12345678',\n",
    "    'all'\n",
    "]\n",
    "\n",
    "BASE_DIR = r'C:\\Users\\darkn\\PycharmProjects\\ChemGPT\\out\\new_data_gpt\\ablation'\n",
    "\n",
    "TYPES = ['LUMO', 'HOMO']\n",
    "\n",
    "def generate_core_combination_data(CORE_LIST, NAME):\n",
    "    for TYPE in TYPES:\n",
    "        test_list = []\n",
    "        for folder in os.listdir(BASE_DIR):\n",
    "            for df_name in CORE_LIST:\n",
    "                if TYPE in folder and df_name in folder:\n",
    "                    df = pd.read_csv(os.path.join(BASE_DIR, folder + '/valid.csv'))\n",
    "                    test_list.append(df)\n",
    "                    path = os.path.join(BASE_DIR, folder)\n",
    "        test_df = pd.concat(test_list)\n",
    "\n",
    "        train_df = pd.read_csv(os.path.join(path, 'train.csv'))\n",
    "        duplicate = train_df.merge(test_df, on=['smiles', 'target'])\n",
    "        train_df = train_df.append(duplicate)\n",
    "        train_df = train_df.drop_duplicates(subset='smiles', keep=False)\n",
    "        train_df.columns = ['prompt', 'completion']\n",
    "        test_df.columns = ['prompt', 'completion']\n",
    "        train_df['completion'] = train_df['completion'].astype(str)\n",
    "        test_df['completion'] = test_df['completion'].astype(str)\n",
    "        train_df.to_csv('train_core_{}_{}.csv'.format(TYPE, NAME), index=False)\n",
    "        test_df.to_csv('test_core_{}_{}.csv'.format(TYPE, NAME), index=False)\n",
    "        write_file(train_df, test_df, '{}_{}'.format(TYPE, NAME))\n",
    "        \n",
    "for CORE_LIST, NAME in zip(CORE_LISTS, NAME_POSTFIXS):\n",
    "    generate_core_combination_data(CORE_LIST, NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
