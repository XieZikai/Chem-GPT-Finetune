{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfef9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data.data_preprocess import generate_classification_dataset, generate_core_train_test_by_equipartition, write_file, generate_classification_dataset_by_equipartition, json_to_csv\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "from openai.cli import FineTune\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from gpt_attacker import Attacker\n",
    "import math\n",
    "import re\n",
    "import copy\n",
    "from utils import replace_smiles_with_missing\n",
    "import chemprop\n",
    "import tqdm\n",
    "from io import StringIO\n",
    "from utils import SMART_LIST\n",
    "import warnings\n",
    "\n",
    "openai.api_key = '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'\n",
    "COLUMN = 'LUMO'\n",
    "NUM_CLASS = 3\n",
    "SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e83a35",
   "metadata": {},
   "source": [
    "# 1. Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5baee56",
   "metadata": {},
   "source": [
    "## Troisi dataset (small molecules) generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6103d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [2, 4, 6, 8]\n",
    "trials = 3\n",
    "datasets = ['HOMO', 'LUMO']\n",
    "df = pd.read_csv('./data/CSD_EES_DB.csv')\n",
    "\n",
    "for dataset in datasets:\n",
    "    for split in splits:\n",
    "        for trial in range(trials):\n",
    "            df_train, df_test = generate_classification_dataset_by_equipartition(column=dataset, df=df, num_class=NUM_CLASS, split=split/10)\n",
    "            write_file(df_train, df_test, '_{}_{}_{}'.format(str(split/10), dataset, str(trial)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf915ce9",
   "metadata": {},
   "source": [
    "# 2. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2ab157",
   "metadata": {},
   "source": [
    "## Troisi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f791e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script shows the fine-tuning process of one folder (train-validation dataset pair).\n",
    "# Please use the same method to fine-tune GPT-3 on other datasets. \n",
    "\n",
    "BASE_DIR = './data/out'\n",
    "folder_name = '20231012_145053__0.8_HOMO_1'\n",
    "folder_dir = os.path.join(BASE_DIR, folder_name)\n",
    "\n",
    "# generate data for chemprop\n",
    "json_to_csv(folder_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765760f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data\n",
    "\n",
    "upload_train = openai.File.create(\n",
    "    file=open(os.path.join(folder_dir, 'train.jsonl'), 'rb'),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "train_file_id = upload_train.id\n",
    "\n",
    "upload_valid = openai.File.create(\n",
    "    file=open(os.path.join(folder_dir, 'valid.jsonl'), 'rb'),\n",
    "    purpose='fine-tune'\n",
    ")\n",
    "valid_file_id = upload_valid.id\n",
    "\n",
    "# submit fine-tuning job\n",
    "\n",
    "fine_tune_response = openai.FineTune.create(\n",
    "    training_file=train_file_id,\n",
    "    validation_file=valid_file_id\n",
    ")\n",
    "\n",
    "print('Fine-tuning job submitted, please hold this job id: {}'.format(fine_tune_response.id))\n",
    "fine_tune_id = fine_tune_response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fff983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use fine_tune_id if you wish to evaluate a fine-tuned model manually\n",
    "\n",
    "fine_tune_id = 'ft-swGhuUiQ7LT9I5FxvHvnThGX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6656f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve_response = openai.FineTune.retrieve(fine_tune_response.id)\n",
    "retrieve_response = openai.FineTune.retrieve(fine_tune_id)\n",
    "fine_tuned_model_id = retrieve_response.fine_tuned_model\n",
    "if fine_tuned_model_id is None:\n",
    "    print('Model is still fine-tuning, please wait.')\n",
    "else:\n",
    "    print('Fine-tuning completed, please hold this model id: {}'.format(fine_tuned_model_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9149ada",
   "metadata": {},
   "source": [
    "## Test set confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data\n",
    "# test = pd.read_json(os.path.join(folder_dir, 'valid.jsonl'), lines=True)\n",
    "test = pd.read_json(r'C:\\Users\\darkn\\PycharmProjects\\ChemGPT\\out\\new_data_gpt\\small_molecule\\20230701_152137__0.8_HOMO_2\\valid.jsonl', lines=True)\n",
    "\n",
    "fine_tune_id = 'ft-PGPYe12c0ccYl1v8gVtBbUCg'\n",
    "\n",
    "# retrieve_response = openai.FineTune.retrieve(fine_tune_response.id)\n",
    "retrieve_response = openai.FineTune.retrieve(fine_tune_id)\n",
    "fine_tuned_model_id = retrieve_response.fine_tuned_model\n",
    "if fine_tuned_model_id is None:\n",
    "    print('Model is still fine-tuning, please wait.')\n",
    "else:\n",
    "    print('Fine-tuning completed, please hold this model id: {}'.format(fine_tuned_model_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b80103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(test)):\n",
    "    # print(test.iloc[i]['prompt'])\n",
    "    prompt = test.iloc[i]['prompt']\n",
    "    res = openai.Completion.create(model=fine_tuned_model_id, prompt=prompt, max_tokens=1, temperature=0)\n",
    "    # print(res['choices'][0]['text'])\n",
    "    y_true.append(str(test.iloc[i]['completion']))\n",
    "    y_pred.append(str(res['choices'][0]['text']))\n",
    "    # if i == 20:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aab607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix, labels):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Define your class labels if you have a classification problem\n",
    "class_labels = ['Class 0', 'Class 1', 'Class 2']  # Modify this as per your specific problem\n",
    "\n",
    "plot_confusion_matrix(cm, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c271ddb",
   "metadata": {},
   "source": [
    "## Troisi dataset GPT-3.5 embeddings & UMAP 2-D visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e75022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get GPT-3.5 embeddings\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for i in range(len(test)):\n",
    "    # print(test.iloc[i]['prompt'])\n",
    "    prompt = test.iloc[i]['prompt']\n",
    "    embedding = get_embedding(prompt)\n",
    "    embeddings.append(embedding)\n",
    "    # if i == 20:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f81e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array(embeddings)\n",
    "reducer = umap.UMAP(n_neighbors=15, n_components=2)\n",
    "reduced_embedding = reducer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc70b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(reduced_embedding[:, 0], reduced_embedding[:, 1])\n",
    "plt.title(\"UMAP Projection\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
